{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\BI\\anaconda3\\lib\\site-packages\\requests\\__init__.py:78: RequestsDependencyWarning: urllib3 (1.26.9) or chardet (3.0.4) doesn't match a supported version!\n",
      "  warnings.warn(\"urllib3 ({0}) or chardet ({1}) doesn't match a supported \"\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import gluonnlp as nlp\n",
    "import numpy as np\n",
    "from tqdm import tqdm, tqdm_notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#kobert\n",
    "from kobert.utils import get_tokenizer\n",
    "from kobert.pytorch_kobert import get_pytorch_kobert_model\n",
    "#transformers\n",
    "from transformers import AdamW\n",
    "from transformers.optimization import get_cosine_schedule_with_warmup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BERTClassifier(nn.Module):\n",
    "    def __init__(self,\n",
    "                 bert,\n",
    "                 hidden_size = 768,\n",
    "                 num_classes=7,   ##클래스 수 조정##\n",
    "                 dr_rate=None,\n",
    "                 params=None):\n",
    "        super(BERTClassifier, self).__init__()\n",
    "        self.bert = bert\n",
    "        self.dr_rate = dr_rate\n",
    "                 \n",
    "        self.classifier = nn.Linear(hidden_size , num_classes)\n",
    "        if dr_rate:\n",
    "            self.dropout = nn.Dropout(p=dr_rate)\n",
    "    \n",
    "    def gen_attention_mask(self, token_ids, valid_length):\n",
    "        attention_mask = torch.zeros_like(token_ids)\n",
    "        for i, v in enumerate(valid_length):\n",
    "            attention_mask[i][:v] = 1\n",
    "        return attention_mask.float()\n",
    "\n",
    "    def forward(self, token_ids, valid_length, segment_ids):\n",
    "        attention_mask = self.gen_attention_mask(token_ids, valid_length)\n",
    "        \n",
    "        _, pooler = self.bert(input_ids = token_ids, token_type_ids = segment_ids.long(), attention_mask = attention_mask.float().to(token_ids.device))\n",
    "        if self.dr_rate:\n",
    "            out = self.dropout(pooler)\n",
    "        return self.classifier(out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "using cached model. c:\\Users\\BI\\Desktop\\KoBert\\KoBERT-master\\.cache\\kobert_v1.zip\n",
      "using cached model. c:\\Users\\BI\\Desktop\\KoBert\\KoBERT-master\\.cache\\kobert_news_wiki_ko_cased-1087f8699e.spiece\n"
     ]
    }
   ],
   "source": [
    "bertmodel, vocab = get_pytorch_kobert_model()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "!pip install torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = torch.load('C:/Users/BI/Desktop/KoBert/KoBERT-master/c.pth',map_location=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# BERT 모델에 들어가기 위한 dataset을 만들어주는 클래스\n",
    "class BERTDataset(Dataset):\n",
    "    def __init__(self, dataset, sent_idx, label_idx, bert_tokenizer, max_len,\n",
    "                 pad, pair):\n",
    "        transform = nlp.data.BERTSentenceTransform(\n",
    "            bert_tokenizer, max_seq_length=max_len, pad=pad, pair=pair)\n",
    "\n",
    "        self.sentences = [transform([i[sent_idx]]) for i in dataset]\n",
    "        self.labels = [np.int32(i[label_idx]) for i in dataset]\n",
    "\n",
    "    def __getitem__(self, i):\n",
    "        return (self.sentences[i] + (self.labels[i], ))\n",
    "\n",
    "    def __len__(self):\n",
    "        return (len(self.labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_len = 64\n",
    "batch_size = 64\n",
    "warmup_ratio = 0.1\n",
    "num_epochs = 5\n",
    "max_grad_norm = 1\n",
    "log_interval = 200\n",
    "learning_rate =  5e-5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "using cached model. c:\\Users\\BI\\Desktop\\KoBert\\KoBERT-master\\.cache\\kobert_news_wiki_ko_cased-1087f8699e.spiece\n"
     ]
    }
   ],
   "source": [
    "#토큰화\n",
    "tokenizer = get_tokenizer()\n",
    "tok = nlp.data.BERTSPTokenizer(tokenizer, vocab, lower=False)\n",
    "def predict(predict_sentence):\n",
    "\n",
    "    data = [predict_sentence, '0']\n",
    "    dataset_another = [data]\n",
    "\n",
    "    another_test = BERTDataset(dataset_another, 0, 1, tok, max_len, True, False)\n",
    "    test_dataloader = torch.utils.data.DataLoader(another_test, batch_size=batch_size, num_workers=0)\n",
    "    \n",
    "    model.eval()\n",
    "\n",
    "    for batch_id, (token_ids, valid_length, segment_ids, label) in enumerate(test_dataloader):\n",
    "        token_ids = token_ids.long().to(device)\n",
    "        segment_ids = segment_ids.long().to(device)\n",
    "\n",
    "        valid_length= valid_length\n",
    "        label = label.long().to(device)\n",
    "\n",
    "        out = model(token_ids, valid_length, segment_ids)\n",
    "\n",
    "\n",
    "        test_eval=[]\n",
    "        for i in out:\n",
    "            logits=i\n",
    "            logits = logits.detach().cpu().numpy()\n",
    "\n",
    "            if np.argmax(logits) == 0:\n",
    "                test_eval.append(\"공포가\")\n",
    "            elif np.argmax(logits) == 1:\n",
    "                test_eval.append(\"놀람이\")\n",
    "            elif np.argmax(logits) == 2:\n",
    "                test_eval.append(\"분노가\")\n",
    "            elif np.argmax(logits) == 3:\n",
    "                test_eval.append(\"슬픔이\")\n",
    "            elif np.argmax(logits) == 4:\n",
    "                test_eval.append(\"중립이\")\n",
    "            elif np.argmax(logits) == 5:\n",
    "                test_eval.append(\"행복이\")\n",
    "            elif np.argmax(logits) == 6:\n",
    "                test_eval.append(\"혐오가\")\n",
    "    return np.argmax(logits)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Connected by ('127.0.0.1', 58028)\n",
      "Received from ('127.0.0.1', 58028) 아 진짜열받는다\n",
      "2\n",
      "Received from ('127.0.0.1', 58028) \n",
      "1\n",
      "except :  ('127.0.0.1', 58028)\n",
      "Connected by ('127.0.0.1', 58032)\n",
      "Received from ('127.0.0.1', 58032) 아 진짜열받는다\n",
      "2\n",
      "Received from ('127.0.0.1', 58032) \n",
      "1\n",
      "except :  ('127.0.0.1', 58032)\n",
      "Connected by ('127.0.0.1', 58041)\n",
      "Received from ('127.0.0.1', 58041) \n",
      "1\n",
      "Received from ('127.0.0.1', 58041) \n",
      "1\n",
      "except :  ('127.0.0.1', 58041)\n",
      "Connected by ('127.0.0.1', 58042)\n",
      "Received from ('127.0.0.1', 58042) zzzzzzzzzz\n",
      "4\n",
      "Received from ('127.0.0.1', 58042) \n",
      "1\n",
      "except :  ('127.0.0.1', 58042)\n",
      "Connected by ('127.0.0.1', 58043)\n",
      "Received from ('127.0.0.1', 58043) 아 진짜 열받는다..\n",
      "2\n",
      "Received from ('127.0.0.1', 58043) \n",
      "1\n",
      "except :  ('127.0.0.1', 58043)\n",
      "Connected by ('127.0.0.1', 58045)\n",
      "Received from ('127.0.0.1', 58045) 아 진짜 열받는다;;\n",
      "2\n",
      "Received from ('127.0.0.1', 58045) \n",
      "1\n",
      "except :  ('127.0.0.1', 58045)\n",
      "Connected by ('127.0.0.1', 58313)\n",
      "Received from ('127.0.0.1', 58313) 아 진짜 열받는다;;\n",
      "2\n",
      "Received from ('127.0.0.1', 58313) \n",
      "1\n",
      "except :  ('127.0.0.1', 58313)\n",
      "Connected by ('127.0.0.1', 58352)\n",
      "Received from ('127.0.0.1', 58352) \n",
      "1\n",
      "Received from ('127.0.0.1', 58352) \n",
      "1\n",
      "except :  ('127.0.0.1', 58352)\n"
     ]
    }
   ],
   "source": [
    "import socket, threading\n",
    "def binder(client_socket, addr):\n",
    "    print('Connected by', addr);\n",
    "    try:\n",
    "        while True:\n",
    "            data = client_socket.recv(4);\n",
    "            length = int.from_bytes(data, \"big\");\n",
    "            data = client_socket.recv(length);\n",
    "            msg = data.decode();\n",
    "            print('Received from', addr, msg);\n",
    "            msg = predict(msg)\n",
    "            msg = str(msg)\n",
    "            print(msg)\n",
    "            data = msg.encode();\n",
    "            length = len(data);\n",
    "            client_socket.sendall(length.to_bytes(4, byteorder='big'))\n",
    "            client_socket.sendall(data);\n",
    "    except:\n",
    "        print(\"except : \" , addr);\n",
    "    finally:\n",
    "        client_socket.close();\n",
    "\n",
    "server_socket = socket.socket(socket.AF_INET, socket.SOCK_STREAM);\n",
    "server_socket.setsockopt(socket.SOL_SOCKET, socket.SO_REUSEADDR, 1);\n",
    "server_socket.bind(('', 9999));\n",
    "server_socket.listen();\n",
    "try:\n",
    "    while True:\n",
    "        client_socket, addr = server_socket.accept();\n",
    "        th = threading.Thread(target=binder, args = (client_socket,addr));\n",
    "        th.start();\n",
    "except:\n",
    "    print(\"server\");\n",
    "finally:\n",
    "    server_socket.close();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "P1 대기시간 :  -8 \t 반환시간 :  -5\n",
      "P2 대기시간 :  1 \t 반환시간 :  2\n",
      "P3 대기시간 :  3 \t 반환시간 :  12\n",
      "P4 대기시간 :  10 \t 반환시간 :  12\n",
      "P5 대기시간 :  11 \t 반환시간 :  15\n"
     ]
    }
   ],
   "source": [
    "process=[\n",
    "    ['P1', 8, 3],\n",
    "    ['P2', 2, 1],\n",
    "    ['P3', 1, 9],\n",
    "    ['P4', 3, 2],\n",
    "    ['P5', 4, 4]\n",
    "]\n",
    "res=[]\n",
    "\n",
    "prirun = 0\n",
    "run = 0\n",
    "\n",
    "\n",
    "\n",
    "for a in range(0, len(process)) :\n",
    "    res.append([])\n",
    "    res[0].append(process[a][0])\n",
    "    run += prirun\n",
    "    arrive = process[a][1]\n",
    "    waittime=run-arrive\n",
    "    res.append([])\n",
    "    res[1].append(waittime)\n",
    "    returntime = waittime + process[a][2]\n",
    "    res.append([])\n",
    "    res[2].append(returntime)\n",
    "    prirun = process[a][2]\n",
    "\n",
    "\n",
    "for p in range(0, len(process)) :\n",
    "    print(res[0][p], \"대기시간 : \", res[1][p] ,\"\\t\", \"반환시간 : \", res[2][p])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Enter the number of process: \n",
      "Enter the burst time of the processes: \n",
      "\n",
      "\n",
      "\n",
      "Process\t  Burst Time\t  Waiting Time\t  Turn Around Time\n",
      "0\t\t1\t\t0\t\t1\n",
      "\n",
      "\n",
      "1\t\t8\t\t1\t\t9\n",
      "\n",
      "\n",
      "2\t\t3\t\t9\t\t12\n",
      "\n",
      "\n"
     ]
    },
    {
     "ename": "IndexError",
     "evalue": "list index out of range",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_7900/3043779843.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     25\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     26\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mn\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 27\u001b[1;33m    \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m+\u001b[0m\u001b[1;34m\"\\t\\t\"\u001b[0m\u001b[1;33m+\u001b[0m\u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbt\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m+\u001b[0m\u001b[1;34m\"\\t\\t\"\u001b[0m\u001b[1;33m+\u001b[0m\u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mwt\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m+\u001b[0m\u001b[1;34m\"\\t\\t\"\u001b[0m\u001b[1;33m+\u001b[0m\u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtat\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     28\u001b[0m    \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"\\n\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     29\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mIndexError\u001b[0m: list index out of range"
     ]
    }
   ],
   "source": [
    "bt=[]\n",
    "print(\"Enter the number of process: \")\n",
    "n=int(input())\n",
    "print(\"Enter the burst time of the processes: \\n\")\n",
    "bt=list(map(int, input().split()))\n",
    "\n",
    "wt=[]\n",
    "avgwt=0\n",
    "tat=[]\n",
    "avgtat=0\n",
    "\n",
    "wt.insert(0,0)\n",
    "tat.insert(0,bt[0])\n",
    "\n",
    "for i in range(1,len(bt)):\n",
    "   wt.insert(i,wt[i-1]+bt[i-1])\n",
    "   tat.insert(i,wt[i]+bt[i])\n",
    "   avgwt+=wt[i]\n",
    "   avgtat+=tat[i]\n",
    "\n",
    "avgwt=float(avgwt)/n\n",
    "avgtat=float(avgtat)/n\n",
    "print(\"\\n\")\n",
    "print(\"Process\\t  Burst Time\\t  Waiting Time\\t  Turn Around Time\")\n",
    "\n",
    "for i in range(0,n):\n",
    "   print(str(i)+\"\\t\\t\"+str(bt[i])+\"\\t\\t\"+str(wt[i])+\"\\t\\t\"+str(tat[i]))\n",
    "   print(\"\\n\")\n",
    "\n",
    "print(\"Average Waiting time is: \"+str(avgwt))\n",
    "print(\"Average Turn Arount Time is: \"+str(avgtat))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "ename": "IndentationError",
     "evalue": "unindent does not match any outer indentation level (<tokenize>, line 18)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  File \u001b[1;32m\"<tokenize>\"\u001b[1;36m, line \u001b[1;32m18\u001b[0m\n\u001b[1;33m    '''\u001b[0m\n\u001b[1;37m    ^\u001b[0m\n\u001b[1;31mIndentationError\u001b[0m\u001b[1;31m:\u001b[0m unindent does not match any outer indentation level\n"
     ]
    }
   ],
   "source": [
    "class FCFS:\n",
    "    def processData(self, no_of_processes):\n",
    "        process_data = []\n",
    "        for i in range(no_of_processes):\n",
    "            temporary = []\n",
    "            process_id = int(input(\"Enter Process ID: \"))\n",
    "\n",
    "            arrival_time = int(input(\"Enter Arrival Time: \"))\n",
    "\n",
    "            burst_time = int(input(f\"Enter Burst Time for Process {process_id}: \"))\n",
    "\n",
    "            temporary.extend([process_id, arrival_time, burst_time])\n",
    "            process_data.append(temporary)\n",
    "        FCFS.schedulingProcess(self, process_data)\n",
    "\n",
    "    def schedulingProcess(self, process_data):\n",
    "        process_data.sort(key=lambda x: x[1])\n",
    "       '''\n",
    "       Sort according to Arrival Time \n",
    "       '''\n",
    "        start_time = []\n",
    "        exit_time = []\n",
    "        s_time = 0\n",
    "        for i in range(len(process_data)):\n",
    "            if s_time < process_data[i][1]:\n",
    "                s_time = process_data[i][1]\n",
    "            start_time.append(s_time)\n",
    "            s_time = s_time + process_data[i][2]\n",
    "            e_time = s_time\n",
    "            exit_time.append(e_time)\n",
    "            process_data[i].append(e_time)\n",
    "        t_time = FCFS.calculateTurnaroundTime(self, process_data)\n",
    "        w_time = FCFS.calculateWaitingTime(self, process_data)\n",
    "        FCFS.printData(self, process_data, t_time, w_time)\n",
    "\n",
    "    def calculateTurnaroundTime(self, process_data):\n",
    "        total_turnaround_time = 0\n",
    "        for i in range(len(process_data)):\n",
    "            turnaround_time = process_data[i][3] - process_data[i][1]\n",
    "            '''\n",
    "            turnaround_time = completion_time - arrival_time\n",
    "            '''\n",
    "            total_turnaround_time = total_turnaround_time + turnaround_time\n",
    "            process_data[i].append(turnaround_time)\n",
    "        average_turnaround_time = total_turnaround_time / len(process_data)\n",
    "        '''\n",
    "        average_turnaround_time = total_turnaround_time / no_of_processes\n",
    "        '''\n",
    "        return average_turnaround_time\n",
    "\n",
    "    def calculateWaitingTime(self, process_data):\n",
    "        total_waiting_time = 0\n",
    "        for i in range(len(process_data)):\n",
    "            waiting_time = process_data[i][4] - process_data[i][2]\n",
    "            '''\n",
    "            waiting_time = turnaround_time - burst_time\n",
    "            '''\n",
    "            total_waiting_time = total_waiting_time + waiting_time\n",
    "            process_data[i].append(waiting_time)\n",
    "        average_waiting_time = total_waiting_time / len(process_data)\n",
    "        '''\n",
    "        average_waiting_time = total_waiting_time / no_of_processes\n",
    "        '''\n",
    "        return average_waiting_time\n",
    "\n",
    "    def printData(self, process_data, average_turnaround_time, average_waiting_time):\n",
    "\n",
    "        print(\"Process_ID  Arrival_Time  Burst_Time  Completion_Time  Turnaround_Time  Waiting_Time\")\n",
    "\n",
    "        for i in range(len(process_data)):\n",
    "            for j in range(len(process_data[i])):\n",
    "                print(process_data[i][j], end=\"\t\t\t\t\")\n",
    "            print()\n",
    "\n",
    "        print(f'Average Turnaround Time: {average_turnaround_time}')\n",
    "\n",
    "        print(f'Average Waiting Time: {average_waiting_time}')\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "\n",
    "    no_of_processes = int(input(\"Enter number of processes: \"))\n",
    "\n",
    "    fcfs = FCFS()\n",
    "    fcfs.processData(no_of_processes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "620f6301a62a5d8554821913c15b412b2638f092aff1ec83c3aa2df3c15bd81d"
  },
  "kernelspec": {
   "display_name": "Python 3.9.7 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
